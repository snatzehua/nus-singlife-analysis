{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "agents = pd.read_excel(\"/Users/snatzehua/Downloads/nus_agent_info_df.xlsx\")\n",
    "policies = pd.read_excel(\"/Users/snatzehua/Downloads/nus_policy_info_df.xlsx\")\n",
    "clients = pd.read_excel(\"/Users/snatzehua/Downloads/nus_client_info_df.xlsx\")\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agntnum</th>\n",
       "      <th>agent_age</th>\n",
       "      <th>agent_gender</th>\n",
       "      <th>agent_marital</th>\n",
       "      <th>agent_tenure</th>\n",
       "      <th>cnt_converted</th>\n",
       "      <th>annual_premium_cnvrt</th>\n",
       "      <th>pct_lapsed</th>\n",
       "      <th>pct_cancel</th>\n",
       "      <th>pct_inforce</th>\n",
       "      <th>pct_prod_0_cnvrt</th>\n",
       "      <th>pct_prod_1_cnvrt</th>\n",
       "      <th>pct_prod_2_cnvrt</th>\n",
       "      <th>pct_prod_3_cnvrt</th>\n",
       "      <th>pct_prod_4_cnvrt</th>\n",
       "      <th>pct_prod_5_cnvrt</th>\n",
       "      <th>pct_prod_6_cnvrt</th>\n",
       "      <th>pct_prod_7_cnvrt</th>\n",
       "      <th>pct_prod_8_cnvrt</th>\n",
       "      <th>pct_prod_9_cnvrt</th>\n",
       "      <th>pct_SX0_unknown</th>\n",
       "      <th>pct_SX1_male</th>\n",
       "      <th>pct_SX2_female</th>\n",
       "      <th>pct_AG01_lt20</th>\n",
       "      <th>pct_AG02_20to24</th>\n",
       "      <th>pct_AG03_25to29</th>\n",
       "      <th>pct_AG04_30to34</th>\n",
       "      <th>pct_AG05_35to39</th>\n",
       "      <th>pct_AG06_40to44</th>\n",
       "      <th>pct_AG07_45to49</th>\n",
       "      <th>pct_AG08_50to54</th>\n",
       "      <th>pct_AG09_55to59</th>\n",
       "      <th>pct_AG10_60up</th>\n",
       "      <th>cluster</th>\n",
       "      <th>agent_product_expertise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIN:9513</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>1.004900e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>3</td>\n",
       "      <td>['prod_2' 'prod_6']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIN:4310</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>396</td>\n",
       "      <td>1.971080e+05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.083937</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.116162</td>\n",
       "      <td>0.184343</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>6</td>\n",
       "      <td>['prod_6']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIN:4302</td>\n",
       "      <td>39.0</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>853</td>\n",
       "      <td>5.106351e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.711606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109027</td>\n",
       "      <td>0.128957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695193</td>\n",
       "      <td>0.304807</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>0.137163</td>\n",
       "      <td>0.144197</td>\n",
       "      <td>0.177022</td>\n",
       "      <td>0.311841</td>\n",
       "      <td>0.106682</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>6</td>\n",
       "      <td>['prod_4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIN:4996</td>\n",
       "      <td>57.0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>41</td>\n",
       "      <td>554</td>\n",
       "      <td>3.514724e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.584838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0.223827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397112</td>\n",
       "      <td>0.602888</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.128159</td>\n",
       "      <td>0.108303</td>\n",
       "      <td>0.234657</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>0.135379</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>0.037906</td>\n",
       "      <td>6</td>\n",
       "      <td>['prod_7' 'prod_9' 'prod_6' 'prod_0' 'prod_2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIN:3457</td>\n",
       "      <td>38.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>62</td>\n",
       "      <td>1525</td>\n",
       "      <td>1.215380e+06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.640656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114098</td>\n",
       "      <td>0.072131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626885</td>\n",
       "      <td>0.373115</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>0.069508</td>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.215082</td>\n",
       "      <td>0.214426</td>\n",
       "      <td>0.108197</td>\n",
       "      <td>0.084590</td>\n",
       "      <td>0.043279</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>6</td>\n",
       "      <td>['prod_6' 'prod_8']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agntnum  agent_age agent_gender agent_marital  agent_tenure  \\\n",
       "0  AIN:9513       32.0            M             M            15   \n",
       "1  AIN:4310       40.0            M             M            18   \n",
       "2  AIN:4302       39.0            F             M            40   \n",
       "3  AIN:4996       57.0            F             D            41   \n",
       "4  AIN:3457       38.0            M             M            62   \n",
       "\n",
       "   cnt_converted  annual_premium_cnvrt  pct_lapsed  pct_cancel  pct_inforce  \\\n",
       "0             21          1.004900e+04         1.0    0.814954     0.000000   \n",
       "1            396          1.971080e+05         0.6    0.083937     0.429293   \n",
       "2            853          5.106351e+05         0.3    0.017406     0.711606   \n",
       "3            554          3.514724e+05         0.3    0.003623     0.584838   \n",
       "4           1525          1.215380e+06         0.3    0.017523     0.640656   \n",
       "\n",
       "   pct_prod_0_cnvrt  pct_prod_1_cnvrt  pct_prod_2_cnvrt  pct_prod_3_cnvrt  \\\n",
       "0               0.0               0.0          0.285714               0.0   \n",
       "1               0.0               0.0          0.128788               0.0   \n",
       "2               0.0               0.0          0.242673               0.0   \n",
       "3               0.0               0.0          0.194946               0.0   \n",
       "4               0.0               0.0          0.145574               0.0   \n",
       "\n",
       "   pct_prod_4_cnvrt  pct_prod_5_cnvrt  pct_prod_6_cnvrt  pct_prod_7_cnvrt  \\\n",
       "0          0.523810               0.0          0.190476               0.0   \n",
       "1          0.005051               0.0          0.462121               0.0   \n",
       "2          0.083236               0.0          0.436108               0.0   \n",
       "3          0.083032               0.0          0.436823               0.0   \n",
       "4          0.047869               0.0          0.620328               0.0   \n",
       "\n",
       "   pct_prod_8_cnvrt  pct_prod_9_cnvrt  pct_SX0_unknown  pct_SX1_male  \\\n",
       "0          0.000000          0.000000              0.0      0.333333   \n",
       "1          0.292929          0.111111              0.0      0.601010   \n",
       "2          0.109027          0.128957              0.0      0.695193   \n",
       "3          0.061372          0.223827              0.0      0.397112   \n",
       "4          0.114098          0.072131              0.0      0.626885   \n",
       "\n",
       "   pct_SX2_female  pct_AG01_lt20  pct_AG02_20to24  pct_AG03_25to29  \\\n",
       "0        0.666667       0.000000         0.238095         0.142857   \n",
       "1        0.398990       0.012626         0.012626         0.131313   \n",
       "2        0.304807       0.010551         0.030481         0.137163   \n",
       "3        0.602888       0.018051         0.005415         0.009025   \n",
       "4        0.373115       0.013115         0.035410         0.069508   \n",
       "\n",
       "   pct_AG04_30to34  pct_AG05_35to39  pct_AG06_40to44  pct_AG07_45to49  \\\n",
       "0         0.000000         0.000000         0.000000         0.000000   \n",
       "1         0.388889         0.116162         0.184343         0.083333   \n",
       "2         0.144197         0.177022         0.311841         0.106682   \n",
       "3         0.128159         0.108303         0.234657         0.162455   \n",
       "4         0.201311         0.215082         0.214426         0.108197   \n",
       "\n",
       "   pct_AG08_50to54  pct_AG09_55to59  pct_AG10_60up  cluster  \\\n",
       "0         0.238095         0.142857       0.238095        3   \n",
       "1         0.020202         0.040404       0.010101        6   \n",
       "2         0.036342         0.035170       0.010551        6   \n",
       "3         0.135379         0.160650       0.037906        6   \n",
       "4         0.084590         0.043279       0.015082        6   \n",
       "\n",
       "                          agent_product_expertise  \n",
       "0                             ['prod_2' 'prod_6']  \n",
       "1                                      ['prod_6']  \n",
       "2                                      ['prod_4']  \n",
       "3  ['prod_7' 'prod_9' 'prod_6' 'prod_0' 'prod_2']  \n",
       "4                             ['prod_6' 'prod_8']  "
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chdrnum</th>\n",
       "      <th>agntnum</th>\n",
       "      <th>secuityno</th>\n",
       "      <th>occdate</th>\n",
       "      <th>annual_premium</th>\n",
       "      <th>product</th>\n",
       "      <th>flg_main</th>\n",
       "      <th>flg_rider</th>\n",
       "      <th>flg_inforce</th>\n",
       "      <th>flg_lapsed</th>\n",
       "      <th>flg_cancel</th>\n",
       "      <th>flg_expire</th>\n",
       "      <th>flg_converted</th>\n",
       "      <th>product_grp</th>\n",
       "      <th>cust_age_at_purchase_grp</th>\n",
       "      <th>cust_tenure_at_purchase_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PID:281</td>\n",
       "      <td>AIN:62</td>\n",
       "      <td>CIN:6957</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG05_35to39</td>\n",
       "      <td>TNR2_lt1yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PID:280</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:2161</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG04_30to34</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PID:2577</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:16605</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>423.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PID:2578</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:16605</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>217.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PID:305</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:7917</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>432.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG07_45to49</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chdrnum agntnum  secuityno    occdate  annual_premium product  flg_main  \\\n",
       "0   PID:281  AIN:62   CIN:6957 2018-11-12             0.0  prod_8         1   \n",
       "1   PID:280  AIN:63   CIN:2161 2024-02-22             7.0  prod_8         1   \n",
       "2  PID:2577  AIN:63  CIN:16605 2024-08-28           423.0  prod_6         1   \n",
       "3  PID:2578  AIN:63  CIN:16605 2024-08-27           217.0  prod_6         1   \n",
       "4   PID:305  AIN:63   CIN:7917 2024-08-28           432.0  prod_6         1   \n",
       "\n",
       "   flg_rider  flg_inforce  flg_lapsed  flg_cancel  flg_expire  flg_converted  \\\n",
       "0          0            1           0           0           0              1   \n",
       "1          0            1           0           0           0              1   \n",
       "2          0            1           0           0           0              1   \n",
       "3          0            1           0           0           0              1   \n",
       "4          0            1           0           0           0              1   \n",
       "\n",
       "  product_grp cust_age_at_purchase_grp cust_tenure_at_purchase_grp  \n",
       "0        PG:0              AG05_35to39                  TNR2_lt1yr  \n",
       "1        PG:0              AG04_30to34                 TNR4_4to8yr  \n",
       "2        PG:0              AG08_50to54                  TNR5_8yrup  \n",
       "3        PG:0              AG08_50to54                  TNR5_8yrup  \n",
       "4        PG:0              AG07_45to49                 TNR4_4to8yr  "
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secuityno</th>\n",
       "      <th>cltsex</th>\n",
       "      <th>cltdob</th>\n",
       "      <th>marryd</th>\n",
       "      <th>race_desc_map</th>\n",
       "      <th>cltpcode</th>\n",
       "      <th>household_size</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>family_size</th>\n",
       "      <th>household_size_grp</th>\n",
       "      <th>family_size_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIN:14264</td>\n",
       "      <td>F</td>\n",
       "      <td>1993-02-17</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>545686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>HH1_lt40</td>\n",
       "      <td>FS3_40to60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIN:7188</td>\n",
       "      <td>F</td>\n",
       "      <td>1977-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>308364</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>HH2_40to80</td>\n",
       "      <td>FS5_80up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIN:13608</td>\n",
       "      <td>F</td>\n",
       "      <td>1998-02-12</td>\n",
       "      <td>S</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>387393</td>\n",
       "      <td>28.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>HH1_lt40</td>\n",
       "      <td>FS2_20to40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIN:5087</td>\n",
       "      <td>F</td>\n",
       "      <td>1972-10-25</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>640469</td>\n",
       "      <td>84.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>HH3_80to100</td>\n",
       "      <td>FS2_20to40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIN:18531</td>\n",
       "      <td>M</td>\n",
       "      <td>1984-12-27</td>\n",
       "      <td>M</td>\n",
       "      <td>Others</td>\n",
       "      <td>763318</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>HH3_80to100</td>\n",
       "      <td>FS4_60to80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secuityno cltsex     cltdob marryd race_desc_map cltpcode  household_size  \\\n",
       "0  CIN:14264      F 1993-02-17      M       Chinese   545686             1.0   \n",
       "1   CIN:7188      F 1977-06-15      M       Chinese   308364            72.0   \n",
       "2  CIN:13608      F 1998-02-12      S       Chinese   387393            28.0   \n",
       "3   CIN:5087      F 1972-10-25      M       Chinese   640469            84.0   \n",
       "4  CIN:18531      M 1984-12-27      M        Others   763318            92.0   \n",
       "\n",
       "   economic_status  family_size household_size_grp family_size_grp  \n",
       "0             76.0         56.0           HH1_lt40      FS3_40to60  \n",
       "1             96.0         90.0         HH2_40to80        FS5_80up  \n",
       "2             93.0         23.0           HH1_lt40      FS2_20to40  \n",
       "3             51.0         34.0        HH3_80to100      FS2_20to40  \n",
       "4             18.0         73.0        HH3_80to100      FS4_60to80  "
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chdrnum</th>\n",
       "      <th>agntnum</th>\n",
       "      <th>secuityno</th>\n",
       "      <th>occdate</th>\n",
       "      <th>annual_premium</th>\n",
       "      <th>product</th>\n",
       "      <th>flg_main</th>\n",
       "      <th>flg_rider</th>\n",
       "      <th>flg_inforce</th>\n",
       "      <th>flg_lapsed</th>\n",
       "      <th>flg_cancel</th>\n",
       "      <th>flg_expire</th>\n",
       "      <th>flg_converted</th>\n",
       "      <th>product_grp</th>\n",
       "      <th>cust_age_at_purchase_grp</th>\n",
       "      <th>cust_tenure_at_purchase_grp</th>\n",
       "      <th>agent_age</th>\n",
       "      <th>agent_gender</th>\n",
       "      <th>agent_marital</th>\n",
       "      <th>agent_tenure</th>\n",
       "      <th>cnt_converted</th>\n",
       "      <th>annual_premium_cnvrt</th>\n",
       "      <th>pct_lapsed</th>\n",
       "      <th>pct_cancel</th>\n",
       "      <th>pct_inforce</th>\n",
       "      <th>pct_prod_0_cnvrt</th>\n",
       "      <th>pct_prod_1_cnvrt</th>\n",
       "      <th>pct_prod_2_cnvrt</th>\n",
       "      <th>pct_prod_3_cnvrt</th>\n",
       "      <th>pct_prod_4_cnvrt</th>\n",
       "      <th>pct_prod_5_cnvrt</th>\n",
       "      <th>pct_prod_6_cnvrt</th>\n",
       "      <th>pct_prod_7_cnvrt</th>\n",
       "      <th>pct_prod_8_cnvrt</th>\n",
       "      <th>pct_prod_9_cnvrt</th>\n",
       "      <th>pct_SX0_unknown</th>\n",
       "      <th>pct_SX1_male</th>\n",
       "      <th>pct_SX2_female</th>\n",
       "      <th>pct_AG01_lt20</th>\n",
       "      <th>pct_AG02_20to24</th>\n",
       "      <th>pct_AG03_25to29</th>\n",
       "      <th>pct_AG04_30to34</th>\n",
       "      <th>pct_AG05_35to39</th>\n",
       "      <th>pct_AG06_40to44</th>\n",
       "      <th>pct_AG07_45to49</th>\n",
       "      <th>pct_AG08_50to54</th>\n",
       "      <th>pct_AG09_55to59</th>\n",
       "      <th>pct_AG10_60up</th>\n",
       "      <th>cluster</th>\n",
       "      <th>agent_product_expertise</th>\n",
       "      <th>cltsex</th>\n",
       "      <th>cltdob</th>\n",
       "      <th>marryd</th>\n",
       "      <th>race_desc_map</th>\n",
       "      <th>cltpcode</th>\n",
       "      <th>household_size</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>family_size</th>\n",
       "      <th>household_size_grp</th>\n",
       "      <th>family_size_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PID:281</td>\n",
       "      <td>AIN:62</td>\n",
       "      <td>CIN:6957</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG05_35to39</td>\n",
       "      <td>TNR2_lt1yr</td>\n",
       "      <td>31.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>6112.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.243689</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>['prod_9' 'prod_2' 'prod_0' 'prod_0']</td>\n",
       "      <td>F</td>\n",
       "      <td>1982-03-11</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>648146</td>\n",
       "      <td>25.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>HH1_lt40</td>\n",
       "      <td>FS5_80up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PID:280</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:2161</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG04_30to34</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>4560</td>\n",
       "      <td>1045929.756</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>0.854605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.063596</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.761404</td>\n",
       "      <td>0.03114</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.370175</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>0.260307</td>\n",
       "      <td>0.212719</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.121711</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>1</td>\n",
       "      <td>['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']</td>\n",
       "      <td>M</td>\n",
       "      <td>1991-03-18</td>\n",
       "      <td>S</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>680120</td>\n",
       "      <td>57.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>HH2_40to80</td>\n",
       "      <td>FS3_40to60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PID:2577</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:16605</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>423.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>4560</td>\n",
       "      <td>1045929.756</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>0.854605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.063596</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.761404</td>\n",
       "      <td>0.03114</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.370175</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>0.260307</td>\n",
       "      <td>0.212719</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.121711</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>1</td>\n",
       "      <td>['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']</td>\n",
       "      <td>M</td>\n",
       "      <td>1973-04-16</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>640818</td>\n",
       "      <td>56.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>HH2_40to80</td>\n",
       "      <td>FS4_60to80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PID:2578</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:16605</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>217.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>4560</td>\n",
       "      <td>1045929.756</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>0.854605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.063596</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.761404</td>\n",
       "      <td>0.03114</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.370175</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>0.260307</td>\n",
       "      <td>0.212719</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.121711</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>1</td>\n",
       "      <td>['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']</td>\n",
       "      <td>M</td>\n",
       "      <td>1973-04-16</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>640818</td>\n",
       "      <td>56.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>HH2_40to80</td>\n",
       "      <td>FS4_60to80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PID:305</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:7917</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>432.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG07_45to49</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>4560</td>\n",
       "      <td>1045929.756</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>0.854605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.063596</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.761404</td>\n",
       "      <td>0.03114</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.370175</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>0.260307</td>\n",
       "      <td>0.212719</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.121711</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>1</td>\n",
       "      <td>['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']</td>\n",
       "      <td>F</td>\n",
       "      <td>1978-06-20</td>\n",
       "      <td>M</td>\n",
       "      <td>Malay</td>\n",
       "      <td>760401</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>HH1_lt40</td>\n",
       "      <td>FS3_40to60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chdrnum agntnum  secuityno    occdate  annual_premium product  flg_main  \\\n",
       "0   PID:281  AIN:62   CIN:6957 2018-11-12             0.0  prod_8         1   \n",
       "1   PID:280  AIN:63   CIN:2161 2024-02-22             7.0  prod_8         1   \n",
       "2  PID:2577  AIN:63  CIN:16605 2024-08-28           423.0  prod_6         1   \n",
       "3  PID:2578  AIN:63  CIN:16605 2024-08-27           217.0  prod_6         1   \n",
       "4   PID:305  AIN:63   CIN:7917 2024-08-28           432.0  prod_6         1   \n",
       "\n",
       "   flg_rider  flg_inforce  flg_lapsed  flg_cancel  flg_expire  flg_converted  \\\n",
       "0          0            1           0           0           0              1   \n",
       "1          0            1           0           0           0              1   \n",
       "2          0            1           0           0           0              1   \n",
       "3          0            1           0           0           0              1   \n",
       "4          0            1           0           0           0              1   \n",
       "\n",
       "  product_grp cust_age_at_purchase_grp cust_tenure_at_purchase_grp  agent_age  \\\n",
       "0        PG:0              AG05_35to39                  TNR2_lt1yr       31.0   \n",
       "1        PG:0              AG04_30to34                 TNR4_4to8yr       32.0   \n",
       "2        PG:0              AG08_50to54                  TNR5_8yrup       32.0   \n",
       "3        PG:0              AG08_50to54                  TNR5_8yrup       32.0   \n",
       "4        PG:0              AG07_45to49                 TNR4_4to8yr       32.0   \n",
       "\n",
       "  agent_gender agent_marital  agent_tenure  cnt_converted  \\\n",
       "0            M             S             6             47   \n",
       "1            M             S            71           4560   \n",
       "2            M             S            71           4560   \n",
       "3            M             S            71           4560   \n",
       "4            M             S            71           4560   \n",
       "\n",
       "   annual_premium_cnvrt  pct_lapsed  pct_cancel  pct_inforce  \\\n",
       "0              6112.000         0.1    0.243689     0.936170   \n",
       "1           1045929.756         0.1    0.157312     0.854605   \n",
       "2           1045929.756         0.1    0.157312     0.854605   \n",
       "3           1045929.756         0.1    0.157312     0.854605   \n",
       "4           1045929.756         0.1    0.157312     0.854605   \n",
       "\n",
       "   pct_prod_0_cnvrt  pct_prod_1_cnvrt  pct_prod_2_cnvrt  pct_prod_3_cnvrt  \\\n",
       "0               0.0          0.212766          0.319149               0.0   \n",
       "1               0.0          0.041009          0.051974               0.0   \n",
       "2               0.0          0.041009          0.051974               0.0   \n",
       "3               0.0          0.041009          0.051974               0.0   \n",
       "4               0.0          0.041009          0.051974               0.0   \n",
       "\n",
       "   pct_prod_4_cnvrt  pct_prod_5_cnvrt  pct_prod_6_cnvrt  pct_prod_7_cnvrt  \\\n",
       "0          0.000000          0.000000          0.042553          0.000000   \n",
       "1          0.010307          0.033333          0.063596          0.007237   \n",
       "2          0.010307          0.033333          0.063596          0.007237   \n",
       "3          0.010307          0.033333          0.063596          0.007237   \n",
       "4          0.010307          0.033333          0.063596          0.007237   \n",
       "\n",
       "   pct_prod_8_cnvrt  pct_prod_9_cnvrt  pct_SX0_unknown  pct_SX1_male  \\\n",
       "0          0.425532           0.00000         0.042553      0.531915   \n",
       "1          0.761404           0.03114         0.024561      0.605263   \n",
       "2          0.761404           0.03114         0.024561      0.605263   \n",
       "3          0.761404           0.03114         0.024561      0.605263   \n",
       "4          0.761404           0.03114         0.024561      0.605263   \n",
       "\n",
       "   pct_SX2_female  pct_AG01_lt20  pct_AG02_20to24  pct_AG03_25to29  \\\n",
       "0        0.425532       0.000000         0.000000         0.106383   \n",
       "1        0.370175       0.009649         0.022149         0.050439   \n",
       "2        0.370175       0.009649         0.022149         0.050439   \n",
       "3        0.370175       0.009649         0.022149         0.050439   \n",
       "4        0.370175       0.009649         0.022149         0.050439   \n",
       "\n",
       "   pct_AG04_30to34  pct_AG05_35to39  pct_AG06_40to44  pct_AG07_45to49  \\\n",
       "0         0.148936         0.297872         0.148936         0.191489   \n",
       "1         0.260307         0.212719         0.181360         0.121711   \n",
       "2         0.260307         0.212719         0.181360         0.121711   \n",
       "3         0.260307         0.212719         0.181360         0.121711   \n",
       "4         0.260307         0.212719         0.181360         0.121711   \n",
       "\n",
       "   pct_AG08_50to54  pct_AG09_55to59  pct_AG10_60up  cluster  \\\n",
       "0         0.000000         0.000000       0.000000        1   \n",
       "1         0.071711         0.019956       0.011842        1   \n",
       "2         0.071711         0.019956       0.011842        1   \n",
       "3         0.071711         0.019956       0.011842        1   \n",
       "4         0.071711         0.019956       0.011842        1   \n",
       "\n",
       "                                            agent_product_expertise cltsex  \\\n",
       "0                             ['prod_9' 'prod_2' 'prod_0' 'prod_0']      F   \n",
       "1  ['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']      M   \n",
       "2  ['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']      M   \n",
       "3  ['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']      M   \n",
       "4  ['prod_0' 'prod_9' 'prod_9' 'prod_6' 'prod_0' 'prod_0' 'prod_4']      F   \n",
       "\n",
       "      cltdob marryd race_desc_map cltpcode  household_size  economic_status  \\\n",
       "0 1982-03-11      M       Chinese   648146            25.0             78.0   \n",
       "1 1991-03-18      S       Chinese   680120            57.0             31.0   \n",
       "2 1973-04-16      M       Chinese   640818            56.0             30.0   \n",
       "3 1973-04-16      M       Chinese   640818            56.0             30.0   \n",
       "4 1978-06-20      M         Malay   760401            23.0              0.0   \n",
       "\n",
       "   family_size household_size_grp family_size_grp  \n",
       "0         98.0           HH1_lt40        FS5_80up  \n",
       "1         47.0         HH2_40to80      FS3_40to60  \n",
       "2         60.0         HH2_40to80      FS4_60to80  \n",
       "3         60.0         HH2_40to80      FS4_60to80  \n",
       "4         55.0           HH1_lt40      FS3_40to60  "
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(policies, agents, on=\"agntnum\", how=\"left\")\n",
    "merged_df = pd.merge(merged_df, clients, on=\"secuityno\", how=\"left\")\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapping = {\n",
    "    \"AG01_lt20\": 17, \"AG02_20to24\": 22, \"AG03_25to29\": 27, \"AG04_30to34\": 32,\n",
    "    \"AG05_35to39\": 37, \"AG06_40to44\": 42, \"AG07_45to49\": 47, \"AG08_50to54\": 52,\n",
    "    \"AG09_55to59\": 57, \"AG10_60up\": 62\n",
    "}\n",
    "merged_df[\"cltage\"] = merged_df[\"cust_age_at_purchase_grp\"].map(age_mapping)\n",
    "\n",
    "columns_to_fix = [\"agent_age\", \"household_size\", \"economic_status\", \"family_size\", \"cltage\"]\n",
    "median_values = {col: merged_df[col].median() for col in columns_to_fix}\n",
    "\n",
    "# Fill NaNs\n",
    "merged_df.fillna(median_values, inplace=True)\n",
    "\n",
    "# Drop rows where key fields have NaNs\n",
    "merged_df.dropna(subset=[\"cltdob\", \"cltpcode\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO - ADD AGENT PRODUCT EXPERTISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "# merged_df[\"agent_product_expertise\"] = merged_df[\"agent_product_expertise\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "# # Use MultiLabelBinarizer to One-Hot Encode Expertise\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# expertise_ohe = pd.DataFrame(mlb.fit_transform(merged_df[\"agent_product_expertise\"]),\n",
    "#                              columns=mlb.classes_, index=merged_df.index)\n",
    "\n",
    "# # Convert One-Hot to Frequency Encoding (Using Original Lists)\n",
    "# for col in expertise_ohe.columns:\n",
    "#     expertise_ohe[col] = merged_df[\"agent_product_expertise\"].apply(lambda x: x.count(col))\n",
    "\n",
    "# # Ensure Numeric Format\n",
    "# expertise_ohe = expertise_ohe.astype(float)\n",
    "# merged_df = pd.concat([merged_df, expertise_ohe], axis=1)\n",
    "\n",
    "# # X Variables\n",
    "# X_continuous_vars = [\"cltage\", \"household_size\", \"economic_status\", \"family_size\"]\n",
    "# X_categorical_vars = [\"product\", \"product_grp\", \"race_desc_map\"]\n",
    "# X_percentage_vars = []  # Already in 0-1 range\n",
    "\n",
    "# # Y Variables\n",
    "# Y_continuous_vars = [\"agent_age\", \"annual_premium_cnvrt\"]\n",
    "# Y_categorical_vars = [\"agent_marital\"]\n",
    "# Y_percentage_vars = [\"pct_lapsed\", \"pct_cancel\", \"pct_inforce\", \"pct_prod_1_cnvrt\", \"pct_prod_2_cnvrt\", \"pct_prod_3_cnvrt\", \"pct_prod_4_cnvrt\", \"pct_prod_5_cnvrt\", \"pct_prod_6_cnvrt\", \"pct_prod_7_cnvrt\", \"pct_prod_8_cnvrt\", \"pct_prod_9_cnvrt\", \"pct_SX0_unknown\", \"pct_SX1_male\", \"pct_SX2_female\", \"pct_AG01_lt20\", \"pct_AG02_20to24\", \"pct_AG03_25to29\", \"pct_AG04_30to34\", \"pct_AG05_35to39\", \"pct_AG06_40to44\", \"pct_AG07_45to49\", \"pct_AG08_50to54\", \"pct_AG09_55to59\", \"pct_AG10_60up\"]\n",
    "\n",
    "# # Other Relevant Variables\n",
    "# other_vars = [\"agntnum\", \"cltsex\", \"agent_gender\", \"agent_product_expertise\"]\n",
    "\n",
    "# # Drop columns not in the above lists and load data\n",
    "# X_all_vars = X_continuous_vars + X_categorical_vars + X_percentage_vars\n",
    "# Y_all_vars = Y_continuous_vars + Y_categorical_vars + Y_percentage_vars\n",
    "# all_vars = X_all_vars + Y_all_vars + other_vars\n",
    "# df = merged_df.drop(columns=[col for col in merged_df.columns if col not in all_vars])\n",
    "\n",
    "# ### --- Step 1: Keep Percentage Variables Unchanged ---\n",
    "# X_percentage = df[X_percentage_vars]  # Percentages are already in [0,1]\n",
    "# Y_percentage = df[Y_percentage_vars]  # Percentages are already in [0,1]\n",
    "\n",
    "# ### --- Step 2: Apply Min-Max Scaling (0-1) to Continuous Variables ---\n",
    "# X_scaler = MinMaxScaler()\n",
    "# X_continuous = pd.DataFrame(X_scaler.fit_transform(df[X_continuous_vars]), \n",
    "#                             columns=X_continuous_vars, \n",
    "#                             index=df.index)\n",
    "# Y_scaler = MinMaxScaler()\n",
    "# Y_continuous = pd.DataFrame(Y_scaler.fit_transform(df[Y_continuous_vars]), \n",
    "#                             columns=Y_continuous_vars, \n",
    "#                             index=df.index)\n",
    "\n",
    "# ### --- Step 3: Label Encode Categorical Variables ---\n",
    "# X_encoder = OneHotEncoder(sparse_output=False)  # Drop first category to avoid multicollinearity\n",
    "# X_categorical = pd.DataFrame(X_encoder.fit_transform(df[X_categorical_vars]), \n",
    "#                              columns=X_encoder.get_feature_names_out(X_categorical_vars), \n",
    "#                              index=df.index)\n",
    "# Y_encoder = OneHotEncoder(sparse_output=False)  # Drop first category to avoid multicollinearity\n",
    "# Y_categorical = pd.DataFrame(Y_encoder.fit_transform(df[Y_categorical_vars]), \n",
    "#                              columns=Y_encoder.get_feature_names_out(Y_categorical_vars), \n",
    "#                              index=df.index)\n",
    "\n",
    "# ### --- Step 4: Misc ---\n",
    "# cltsex_map = {\"M\": 1, \"F\": 0, \" \": 0.5}  # Handling empty string case\n",
    "# agent_gender_map = {\"M\": 1, \"F\": 0, \"U\": 0.5}  # Handling empty string case\n",
    "# df[\"cltsex\"] = df[\"cltsex\"].map(cltsex_map).fillna(0.5)\n",
    "# df[\"agent_gender\"] = df[\"agent_gender\"].map(cltsex_map).fillna(0.5)\n",
    "\n",
    "# ### --- Step 5: Combine All Processed Features ---\n",
    "# X_final = pd.concat([X_continuous, X_percentage, X_categorical, df[[\"cltsex\"]]], axis=1)\n",
    "# Y_final = pd.concat([Y_continuous, Y_percentage, Y_categorical], axis=1)\n",
    "\n",
    "# ### --- Final Output ---\n",
    "# # print(\"Final Processed X Shape:\", X_final.shape)\n",
    "# print(X_final.head())\n",
    "\n",
    "# # print(\"Final Processed Y Shape:\", Y_final.shape)\n",
    "# print(Y_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Tensor Shape: torch.Size([29263, 9])\n",
      "Y Tensor Shape: torch.Size([29263, 28])\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# # Assume merged_df is already available\n",
    "\n",
    "# # Convert Multi-Label Column to Frequency Encoding\n",
    "# merged_df[\"agent_product_expertise\"] = merged_df[\"agent_product_expertise\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "# expertise_ohe = pd.DataFrame({col: merged_df[\"agent_product_expertise\"].apply(lambda x: x.count(col)) \n",
    "#                               for col in set(sum(merged_df[\"agent_product_expertise\"], []))}, index=merged_df.index)\n",
    "# expertise_ohe = expertise_ohe.astype(float)\n",
    "# merged_df = pd.concat([merged_df, expertise_ohe], axis=1)\n",
    "\n",
    "# # X Variables\n",
    "# X_continuous_vars = [\"cltage\", \"household_size\", \"economic_status\", \"family_size\"]\n",
    "# X_categorical_vars = [\"product\", \"product_grp\", \"race_desc_map\"]\n",
    "# X_percentage_vars = []  # Already in 0-1 range\n",
    "\n",
    "# # Y Variables\n",
    "# Y_continuous_vars = [\"agent_age\", \"annual_premium_cnvrt\"]\n",
    "# Y_categorical_vars = [\"agent_marital\"]\n",
    "# Y_percentage_vars = [\"pct_lapsed\", \"pct_cancel\", \"pct_inforce\", \"pct_prod_1_cnvrt\", \"pct_prod_2_cnvrt\", \n",
    "#                      \"pct_prod_3_cnvrt\", \"pct_prod_4_cnvrt\", \"pct_prod_5_cnvrt\", \"pct_prod_6_cnvrt\", \n",
    "#                      \"pct_prod_7_cnvrt\", \"pct_prod_8_cnvrt\", \"pct_prod_9_cnvrt\", \"pct_SX0_unknown\", \n",
    "#                      \"pct_SX1_male\", \"pct_SX2_female\", \"pct_AG01_lt20\", \"pct_AG02_20to24\", \"pct_AG03_25to29\", \n",
    "#                      \"pct_AG04_30to34\", \"pct_AG05_35to39\", \"pct_AG06_40to44\", \"pct_AG07_45to49\", \n",
    "#                      \"pct_AG08_50to54\", \"pct_AG09_55to59\", \"pct_AG10_60up\"]\n",
    "\n",
    "# # Other Relevant Variables\n",
    "# other_vars = [\"agntnum\", \"cltsex\", \"agent_gender\", \"agent_product_expertise\"]\n",
    "\n",
    "# # Drop columns not in the above lists\n",
    "# X_all_vars = X_continuous_vars + X_categorical_vars + X_percentage_vars\n",
    "# Y_all_vars = Y_continuous_vars + Y_categorical_vars + Y_percentage_vars\n",
    "# all_vars = X_all_vars + Y_all_vars + other_vars\n",
    "# df = merged_df.drop(columns=[col for col in merged_df.columns if col not in all_vars])\n",
    "\n",
    "# ### --- Step 1: Keep Percentage Variables Unchanged ---\n",
    "# X_percentage = df[X_percentage_vars]\n",
    "# Y_percentage = df[Y_percentage_vars]\n",
    "\n",
    "# ### --- Step 2: Apply Min-Max Scaling (0-1) to Continuous Variables ---\n",
    "# X_scaler = MinMaxScaler()\n",
    "# X_continuous = pd.DataFrame(X_scaler.fit_transform(df[X_continuous_vars]), \n",
    "#                             columns=X_continuous_vars, \n",
    "#                             index=df.index)\n",
    "\n",
    "# Y_scaler = MinMaxScaler()\n",
    "# Y_continuous = pd.DataFrame(Y_scaler.fit_transform(df[Y_continuous_vars]), \n",
    "#                             columns=Y_continuous_vars, \n",
    "#                             index=df.index)\n",
    "\n",
    "# ### --- Step 3: Label Encoding for Categorical Variables ---\n",
    "# label_encoders = {}\n",
    "# for col in X_categorical_vars + Y_categorical_vars:\n",
    "#     le = LabelEncoder()\n",
    "#     df[col] = le.fit_transform(df[col])\n",
    "#     label_encoders[col] = le  # Store encoders for later use\n",
    "\n",
    "# X_categorical = df[X_categorical_vars]\n",
    "# Y_categorical = df[Y_categorical_vars]\n",
    "\n",
    "# ### --- Step 4: Mapping Binary Categorical Variables (cltsex, agent_gender) ---\n",
    "# cltsex_map = {\"M\": 1, \"F\": 0, \" \": 0.5}\n",
    "# agent_gender_map = {\"M\": 1, \"F\": 0, \"U\": 0.5}\n",
    "# df[\"cltsex\"] = df[\"cltsex\"].map(cltsex_map).fillna(0.5)\n",
    "# df[\"agent_gender\"] = df[\"agent_gender\"].map(cltsex_map).fillna(0.5)\n",
    "\n",
    "# ### --- Step 5: Combine All Processed Features ---\n",
    "# X_final = pd.concat([X_continuous, X_percentage, X_categorical, df[[\"cltsex\", \"agent_gender\"]]], axis=1)\n",
    "# Y_final = pd.concat([Y_continuous, Y_percentage, Y_categorical], axis=1)\n",
    "\n",
    "# # Convert to PyTorch tensors\n",
    "# X_tensor = torch.tensor(X_final.values, dtype=torch.float32)\n",
    "# Y_tensor = torch.tensor(Y_final.values, dtype=torch.float32)\n",
    "\n",
    "# # Print final tensor shapes\n",
    "# print(\"X Tensor Shape:\", X_tensor.shape)\n",
    "# print(\"Y Tensor Shape:\", Y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final shape: (29263, 9), Y_final shape: (29263, 28)\n",
      "X index range: 0 to 29502\n",
      "Y index range: 0 to 29502\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# print(f\"X_final shape: {X_final.shape}, Y_final shape: {Y_final.shape}\")\n",
    "# print(f\"X index range: {X_final.index.min()} to {X_final.index.max()}\")\n",
    "# print(f\"Y index range: {Y_final.index.min()} to {Y_final.index.max()}\")\n",
    "\n",
    "# print(X_final.isnull().sum().sum())  # Should be 0\n",
    "# print(Y_final.isnull().sum().sum())  # Should be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(8, 8)\n",
      "    (1): Embedding(4, 8)\n",
      "    (2): Embedding(6, 8)\n",
      "  )\n",
      "  (fc1): Linear(in_features=30, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# class NeuralNet(nn.Module):\n",
    "#     def __init__(self, input_dim, cat_dims, embed_dim=8):\n",
    "#         super(NeuralNet, self).__init__()\n",
    "        \n",
    "#         # Embedding layers for categorical variables\n",
    "#         self.embeddings = nn.ModuleList([nn.Embedding(cat_dim, embed_dim) for cat_dim in cat_dims])\n",
    "        \n",
    "#         # Define network layers\n",
    "#         self.fc1 = nn.Linear(input_dim + len(cat_dims) * embed_dim, 64)\n",
    "#         self.fc2 = nn.Linear(64, 32)\n",
    "#         self.fc3 = nn.Linear(32, 1)  # Assuming binary classification\n",
    "        \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.sigmoid = nn.Sigmoid()  # Change as needed\n",
    "\n",
    "#     def forward(self, x_cont, x_cat):\n",
    "#         # Apply embeddings\n",
    "#         x_cat_emb = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "#         x_cat_emb = torch.cat(x_cat_emb, dim=1)\n",
    "\n",
    "#         # Concatenate continuous and categorical embeddings\n",
    "#         x = torch.cat([x_cont, x_cat_emb], dim=1)\n",
    "\n",
    "#         # Forward pass through MLP\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.relu(self.fc2(x))\n",
    "#         x = self.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "# # Define categorical dimensions (add 1 to account for unseen values)\n",
    "# cat_dims = [df[col].nunique() + 1 for col in X_categorical_vars]\n",
    "\n",
    "# # Model Initialization\n",
    "# model = NeuralNet(input_dim=X_continuous.shape[1] + len(X_percentage_vars) + 2,  # 2 for cltsex & agent_gender\n",
    "#                   cat_dims=cat_dims)\n",
    "\n",
    "# # Move model to GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Print model summary\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, X_cont, X_cat, Y):\n",
    "#         self.X_cont = X_cont\n",
    "#         self.X_cat = X_cat\n",
    "#         self.Y = Y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.Y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.X_cont[idx], self.X_cat[idx], self.Y[idx]\n",
    "\n",
    "# # Convert categorical features into a separate tensor\n",
    "# X_cat_tensor = torch.tensor(df[X_categorical_vars].values, dtype=torch.long)  # Long for embeddings\n",
    "# X_cont_tensor = torch.tensor(X_continuous.values, dtype=torch.float32)\n",
    "# Y_tensor = torch.tensor(Y_final.values, dtype=torch.float32)  # Adjust dtype if needed\n",
    "\n",
    "# # Create dataset\n",
    "# dataset = CustomDataset(X_cont_tensor, X_cat_tensor, Y_tensor)\n",
    "\n",
    "# # DataLoader (batch processing)\n",
    "# batch_size = 32\n",
    "# train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x28 and 30x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[660], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cont_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cat_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), Y_batch\u001b[38;5;241m.\u001b[39msqueeze())  \u001b[38;5;66;03m# Ensure shapes match\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/nus-singlife-analysis/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/nus-singlife-analysis/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[658], line 25\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[0;34m(self, x_cont, x_cat)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_cont, x_cat_emb], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Forward pass through MLP\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m~/Documents/GitHub/nus-singlife-analysis/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/nus-singlife-analysis/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/nus-singlife-analysis/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x28 and 30x64)"
     ]
    }
   ],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# # Loss function\n",
    "# criterion = nn.BCELoss()  # Use BCEWithLogitsLoss() if output layer does NOT have sigmoid\n",
    "\n",
    "# # Optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 20  # Adjust as needed\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     total_loss = 0.0\n",
    "#     model.train()  # Set model to training mode\n",
    "\n",
    "#     for X_cont_batch, X_cat_batch, Y_batch in train_loader:\n",
    "#         # Move data to GPU if available\n",
    "#         X_cont_batch = X_cont_batch.to(device)\n",
    "#         X_cat_batch = X_cat_batch.to(device)\n",
    "#         Y_batch = Y_batch.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(X_cont_batch, X_cat_batch)\n",
    "\n",
    "#         # Compute loss\n",
    "#         loss = criterion(outputs.squeeze(), Y_batch.squeeze())  # Ensure shapes match\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Backpropagation\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # Print epoch loss\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()  # Set model to evaluation mode\n",
    "# with torch.no_grad():\n",
    "#     predictions = model(X_cont_tensor.to(device), X_cat_tensor.to(device))\n",
    "#     predictions = predictions.cpu().numpy()\n",
    "\n",
    "# # Convert probabilities to binary labels (for classification)\n",
    "# pred_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# # Print first few predictions\n",
    "# print(pred_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import numpy as np\n",
    "\n",
    "# # ✅ Set random seed for reproducibility\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# # ✅ Convert Pandas DataFrames to PyTorch Tensors\n",
    "# X_tensor = torch.tensor(X_final.values, dtype=torch.float32)\n",
    "# Y_tensor = torch.tensor(Y_final.values, dtype=torch.float32)  # Assume Y_final is mostly continuous\n",
    "\n",
    "# # ✅ Split Data Into Training & Test Sets (80% Train, 20% Test)\n",
    "# train_size = int(0.8 * len(X_tensor))\n",
    "# test_size = len(X_tensor) - train_size\n",
    "# train_dataset, test_dataset = random_split(TensorDataset(X_tensor, Y_tensor), [train_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # ✅ Define Multi-Output Neural Network Model\n",
    "# class MultiOutputNN(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(MultiOutputNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 128)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.fc3 = nn.Linear(64, output_size)  # Output size matches the number of Y_final columns\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.fc1(x))\n",
    "#         x = self.relu2(self.fc2(x))\n",
    "#         x = self.fc3(x)  # Output layer (no activation)\n",
    "#         return x\n",
    "\n",
    "# # ✅ Initialize Model\n",
    "# input_size = X_final.shape[1]\n",
    "# output_size = Y_final.shape[1]\n",
    "# model = MultiOutputNN(input_size, output_size)\n",
    "\n",
    "# # ✅ Apply Xavier Initialization\n",
    "# def initialize_weights(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         nn.init.xavier_uniform_(m.weight)\n",
    "#         nn.init.zeros_(m.bias)\n",
    "\n",
    "# model.apply(initialize_weights)\n",
    "\n",
    "# # ✅ Define Loss Function & Optimizer\n",
    "# loss_function = nn.MSELoss()  # Using Mean Squared Error Loss for all outputs\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=0.01)\n",
    "\n",
    "# # ✅ Learning Rate Scheduler (Reduce LR on Plateau)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# # ✅ Training Loop\n",
    "# epochs = 100\n",
    "# loss_history = []\n",
    "# best_loss = float('inf')\n",
    "# patience = 10\n",
    "# counter = 0\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for batch_X, batch_Y in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         predictions = model(batch_X)\n",
    "#         loss = loss_function(predictions, batch_Y)  # MSELoss for continuous output\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     avg_loss = epoch_loss / len(train_loader)\n",
    "#     loss_history.append(avg_loss)\n",
    "#     print(f\"Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#     # Learning Rate Adjustment\n",
    "#     scheduler.step(avg_loss)\n",
    "\n",
    "#     # Early Stopping\n",
    "#     if avg_loss < best_loss:\n",
    "#         best_loss = avg_loss\n",
    "#         counter = 0\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # ✅ Save Model\n",
    "# torch.save(model.state_dict(), 'multi_output_nn.pth')\n",
    "# print(\"Model training complete and saved!\")\n",
    "\n",
    "# # ✅ Evaluation on Test Set\n",
    "# model.eval()\n",
    "# test_loss = 0\n",
    "# mae_loss = nn.L1Loss()  # Mean Absolute Error for continuous values\n",
    "# total_mae = 0\n",
    "# total_samples = 0\n",
    "# num_categorical_vars = len([col for col in Y_final.columns if 'agent_marital' in col])  # Adjust based on actual categorical vars\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct_classification = 0\n",
    "#     total_classification = 0\n",
    "#     for batch_X, batch_Y in test_loader:\n",
    "#         predictions = model(batch_X)\n",
    "#         loss = loss_function(predictions, batch_Y)  # MSELoss\n",
    "#         test_loss += loss.item()\n",
    "\n",
    "#         # ✅ Compute Mean Absolute Error (Continuous Variables)\n",
    "#         total_mae += mae_loss(predictions[:, :-num_categorical_vars], batch_Y[:, :-num_categorical_vars]).item()\n",
    "#         total_samples += batch_Y.size(0)\n",
    "\n",
    "#         # ✅ Compute Accuracy for Categorical Variables (Handling Binary & One-Hot)\n",
    "#         categorical_actuals = batch_Y[:, -num_categorical_vars:]\n",
    "#         categorical_preds = predictions[:, -num_categorical_vars:]\n",
    "\n",
    "#         if num_categorical_vars > 1:\n",
    "#             categorical_actuals = categorical_actuals.argmax(dim=1)  # One-hot case\n",
    "#             categorical_preds = categorical_preds.argmax(dim=1)\n",
    "#         else:\n",
    "#             categorical_actuals = torch.round(categorical_actuals).long()  # Binary case\n",
    "#             categorical_preds = torch.round(categorical_preds).long()\n",
    "\n",
    "#         correct_classification += (categorical_preds == categorical_actuals).sum().item()\n",
    "#         total_classification += categorical_actuals.size(0)\n",
    "\n",
    "# avg_test_loss = test_loss / len(test_loader)\n",
    "# avg_mae = total_mae / total_samples\n",
    "# classification_accuracy = (correct_classification / total_classification) * 100 if total_classification > 0 else 0\n",
    "\n",
    "# print(f\"Test Loss (MSE): {avg_test_loss:.4f}\")\n",
    "# print(f\"Mean Absolute Error (Continuous Outputs): {avg_mae:.4f}\")\n",
    "# print(f\"Categorical Prediction Accuracy: {classification_accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     sample_X, sample_Y = next(iter(test_loader))\n",
    "#     predictions = model(sample_X)\n",
    "#     print(\"Actual:\", sample_Y[:5])  # First 5 actual labels\n",
    "#     print(\"Predicted:\", predictions[:5])  # First 5 predicted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import numpy as np\n",
    "\n",
    "# # ✅ Set random seed for reproducibility\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# # ✅ Convert Pandas DataFrames to PyTorch Tensors\n",
    "# X_tensor = torch.tensor(X_final.values, dtype=torch.float32)\n",
    "# Y_tensor = torch.tensor(Y_final.values, dtype=torch.float32)  # Assume Y_final is all continuous (modify if categorical)\n",
    "\n",
    "# # ✅ Split Data Into Training & Test Sets (80% Train, 20% Test)\n",
    "# train_size = int(0.8 * len(X_tensor))\n",
    "# test_size = len(X_tensor) - train_size\n",
    "# train_dataset, test_dataset = random_split(TensorDataset(X_tensor, Y_tensor), [train_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # ✅ Define Multi-Output Neural Network Model\n",
    "# class MultiOutputNN(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(MultiOutputNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 128)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.fc3 = nn.Linear(64, output_size)  # Output size matches the number of Y_final columns\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.fc1(x))\n",
    "#         x = self.relu2(self.fc2(x))\n",
    "#         x = self.fc3(x)  # Output layer (no activation)\n",
    "#         return x\n",
    "\n",
    "# # ✅ Initialize Model\n",
    "# input_size = X_final.shape[1]\n",
    "# output_size = Y_final.shape[1]\n",
    "# model = MultiOutputNN(input_size, output_size)\n",
    "\n",
    "# # ✅ Apply Xavier Initialization\n",
    "# def initialize_weights(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         nn.init.xavier_uniform_(m.weight)\n",
    "#         nn.init.zeros_(m.bias)\n",
    "\n",
    "# model.apply(initialize_weights)\n",
    "\n",
    "# # ✅ Define Loss Function & Optimizer\n",
    "# loss_function = nn.MSELoss()  # Since Y_final is mostly continuous, using Mean Squared Error Loss\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=0.01)\n",
    "\n",
    "# # ✅ Learning Rate Scheduler (Reduce LR on Plateau)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# # ✅ Training Loop\n",
    "# epochs = 100\n",
    "# loss_history = []\n",
    "# best_loss = float('inf')\n",
    "# patience = 10\n",
    "# counter = 0\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for batch_X, batch_Y in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         predictions = model(batch_X)\n",
    "#         loss = loss_function(predictions, batch_Y)  # MSELoss for continuous output\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     avg_loss = epoch_loss / len(train_loader)\n",
    "#     loss_history.append(avg_loss)\n",
    "#     print(f\"Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#     # Learning Rate Adjustment\n",
    "#     scheduler.step(avg_loss)\n",
    "\n",
    "#     # Early Stopping\n",
    "#     if avg_loss < best_loss:\n",
    "#         best_loss = avg_loss\n",
    "#         counter = 0\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # ✅ Save Model\n",
    "# torch.save(model.state_dict(), 'multi_output_nn.pth')\n",
    "# print(\"Model training complete and saved!\")\n",
    "\n",
    "# # ✅ Evaluation on Test Set\n",
    "# model.eval()\n",
    "# test_loss = 0\n",
    "# with torch.no_grad():\n",
    "#     for batch_X, batch_Y in test_loader:\n",
    "#         predictions = model(batch_X)\n",
    "#         loss = loss_function(predictions, batch_Y)  # MSELoss\n",
    "#         test_loss += loss.item()\n",
    "\n",
    "# avg_test_loss = test_loss / len(test_loader)\n",
    "# print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Example lists of variable types\n",
    "continuous_vars = [\"agent_age\", \"agent_tenure\", \"annual_premium_cnvrt\", \"cltage\"]\n",
    "percentage_vars = [\"pct_lapsed\", \"pct_cancel\", \"pct_inforce\", \"pct_SX1_male\", \"pct_SX2_female\"]  # Already in 0-1 range\n",
    "categorical_vars = [\"agent_marital\"]\n",
    "\n",
    "# Load dataset (replace with actual dataset)\n",
    "df = merged_df\n",
    "\n",
    "### --- Step 1: Keep Percentage Variables Unchanged ---\n",
    "X_percentage = df[percentage_vars]  # Percentages are already in [0,1]\n",
    "\n",
    "### --- Step 2: Apply Min-Max Scaling (0-1) to Continuous Variables ---\n",
    "scaler = MinMaxScaler()\n",
    "X_continuous = pd.DataFrame(scaler.fit_transform(df[continuous_vars]), \n",
    "                            columns=continuous_vars, \n",
    "                            index=df.index)\n",
    "\n",
    "### --- Step 3: One-Hot Encode Categorical Variables ---\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Drop first category to avoid multicollinearity\n",
    "X_categorical = pd.DataFrame(encoder.fit_transform(df[categorical_vars]), \n",
    "                             columns=encoder.get_feature_names_out(categorical_vars), \n",
    "                             index=df.index)\n",
    "\n",
    "### --- Step 4: Map Gender ---\n",
    "agent_gender_map = {\"M\": 1, \"F\": 0, \"U\": 0.5}\n",
    "cltsex_map = {\"M\": 1, \"F\": 0, \" \": 0.5}  # Handling empty string case\n",
    "\n",
    "df[\"agent_gender\"] = df[\"agent_gender\"].map(agent_gender_map).fillna(0.5)\n",
    "df[\"cltsex\"] = df[\"cltsex\"].map(cltsex_map).fillna(0.5)\n",
    "\n",
    "### --- Step 5: Combine All Processed Features ---\n",
    "X_final = pd.concat([X_continuous, X_percentage, X_categorical, df[[\"agent_gender\", \"cltsex\"]]], axis=1)\n",
    "\n",
    "### --- Final Output ---\n",
    "print(\"Final Processed X Shape:\", X_final.shape)\n",
    "print(X_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Convert DataFrame to PyTorch Tensors\n",
    "X_tensor = torch.tensor(X_final.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(df['agntnum'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "\n",
    "# Split into Train and Test Sets\n",
    "train_size = int(0.8 * len(X_tensor))\n",
    "test_size = len(X_tensor) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(TensorDataset(X_tensor, y_tensor), [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define Neural Network Model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation since CrossEntropyLoss expects raw logits\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "input_size = X_final.shape[1]\n",
    "output_size = len(df['agntnum'].astype('category').cat.categories)\n",
    "model = NeuralNetwork(input_size, output_size)\n",
    "\n",
    "# Apply Xavier Initialization\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# Compute class weights for imbalanced dataset\n",
    "class_counts = df['agntnum'].value_counts().sort_index().values\n",
    "class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float32)\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Define Optimizer with Lower Learning Rate\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)\n",
    "\n",
    "# Training Loop\n",
    "import matplotlib.pyplot as plt\n",
    "loss_history = []\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_X)\n",
    "        loss = loss_function(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    scheduler.step()\n",
    "\n",
    "# Evaluation on Test Set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Plot Loss Curve\n",
    "plt.plot(range(1, epochs+1), loss_history, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "torch.save(model.state_dict(), 'neural_network.pth')\n",
    "print(\"Model training complete and saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
